<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>TTS Research | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="TTS Research" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A summary research for TTS" />
<meta property="og:description" content="A summary research for TTS" />
<link rel="canonical" href="https://bodasadalla98.github.io/Boda-Blog/tts/deeplearning/2021/10/14/Text-To-Speech.html" />
<meta property="og:url" content="https://bodasadalla98.github.io/Boda-Blog/tts/deeplearning/2021/10/14/Text-To-Speech.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-14T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-10-14T00:00:00-05:00","url":"https://bodasadalla98.github.io/Boda-Blog/tts/deeplearning/2021/10/14/Text-To-Speech.html","@type":"BlogPosting","headline":"TTS Research","dateModified":"2021-10-14T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://bodasadalla98.github.io/Boda-Blog/tts/deeplearning/2021/10/14/Text-To-Speech.html"},"description":"A summary research for TTS","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Boda-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://bodasadalla98.github.io/Boda-Blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/Boda-Blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Boda-Blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Boda-Blog/about/">About Me</a><a class="page-link" href="/Boda-Blog/search/">Search</a><a class="page-link" href="/Boda-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">TTS Research</h1><p class="page-description">A summary research for TTS</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-14T00:00:00-05:00" itemprop="datePublished">
        Oct 14, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Boda-Blog/categories/#TTS">TTS</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Boda-Blog/categories/#Deeplearning">Deeplearning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/BodaSadalla98/Boda-Blog/tree/master/_notebooks/2021-10-14-Text-To-Speech.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Boda-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/BodaSadalla98/Boda-Blog/master?filepath=_notebooks%2F2021-10-14-Text-To-Speech.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Boda-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/BodaSadalla98/Boda-Blog/blob/master/_notebooks/2021-10-14-Text-To-Speech.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Boda-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h3"><a href="#TTS">TTS </a></li>
<li class="toc-entry toc-h2"><a href="#End-to-end-TTS">End-to-end TTS </a></li>
<li class="toc-entry toc-h2"><a href="#Wavenet">Wavenet </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Based-on:">Based on: </a></li>
<li class="toc-entry toc-h3"><a href="#Wavenet-V1">Wavenet V1 </a></li>
<li class="toc-entry toc-h3"><a href="#Wavenet-V2">Wavenet V2 </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#End-to-end-adversarial-TTS">End-to-end adversarial TTS </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Based-on:">Based on: </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Tacotron2">Tacotron2 </a>
<ul>
<li class="toc-entry toc-h3"><a href="#based-on:">based on: </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-10-14-Text-To-Speech.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TTS">
<a class="anchor" href="#TTS" aria-hidden="true"><span class="octicon octicon-link"></span></a>TTS<a class="anchor-link" href="#TTS"> </a>
</h3>
<p>TTS can be viewed as a sequence-to-sequence mapping problem; from a sequence of discrete symbols
(text) to a real-valued time series (speech signals). A typical TTS pipeline has two parts; 1)
text analysis and 2) speech synthesis. The text analysis part typically includes a number of natural
language processing (NLP) steps, such as sentence segmentation, word segmentation, text normalization,
part-of-speech (POS) tagging, and grapheme-to-phoneme (G2P) conversion. It takes a word
sequence as input and outputs a phoneme sequence with a variety of linguistic contexts. The speech
synthesis part takes the context-dependent phoneme sequence as its input and outputs a synthesized
speech waveform.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="End-to-end-TTS">
<a class="anchor" href="#End-to-end-TTS" aria-hidden="true"><span class="octicon octicon-link"></span></a>End-to-end TTS<a class="anchor-link" href="#End-to-end-TTS"> </a>
</h2>
<ul>
<li>easier pipeline</li>
<li>better peformance </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wavenet">
<a class="anchor" href="#Wavenet" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wavenet<a class="anchor-link" href="#Wavenet"> </a>
</h2>
<h3 id="Based-on:">
<a class="anchor" href="#Based-on:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Based on:<a class="anchor-link" href="#Based-on:"> </a>
</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=YyUXG-BfDbE">DeepMind's Wavenet</a></li>
<li><a href="https://www.kdnuggets.com/2020/07/deep-learning-signal-processing.html">https://www.kdnuggets.com/2020/07/deep-learning-signal-processing.html</a></li>
<li><a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio">https://deepmind.com/blog/article/wavenet-generative-model-raw-audio</a></li>
</ul>
<h3 id="Wavenet-V1">
<a class="anchor" href="#Wavenet-V1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wavenet V1<a class="anchor-link" href="#Wavenet-V1"> </a>
</h3>
<p>before wavenet, ther was two methods:</p>
<ul>
<li>generative method, which would produce the over all song of the sentece well, but would fail to produce the individual sounds well</li>
<li>
<p>concatinative: we use a huge corpus of phonatics and concatinate them together to procude a whole sentence, this way we would procuce the individual sounds correctly, but we would lose the song of the sentence</p>
</li>
<li>
<p>wavenet: tries to do both of the above methods, it also can change the speaker by changing some parameters</p>
</li>
<li>
<p>data output:   16 khz rate</p>
</li>
<li>
<p>we  cant use normal RNN as the max seq length around 50</p>
</li>
<li>
<p>they used dilated CNNs:</p>
<ul>
<li>can have very long look back</li>
<li>fast to train</li>
</ul>
</li>
</ul>
<p>This paper has presented WaveNet, a deep generative model of audio data that operates directly at
the waveform level. WaveNets are autoregressive and combine causal filters with dilated convolutions
to allow their receptive fields to grow exponentially with depth, which is important to model
the long-range temporal dependencies in audio signals. We have shown how WaveNets can be conditioned
on other inputs in a global (e.g. speaker identity) or local way (e.g. linguistic features).
When applied to TTS, WaveNets produced samples that outperform the current best TTS systems
in subjective naturalness. Finally, WaveNets showed very promising results when applied to music
audio modeling and speech recognition.</p>
<h3 id="Wavenet-V2">
<a class="anchor" href="#Wavenet-V2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Wavenet V2<a class="anchor-link" href="#Wavenet-V2"> </a>
</h3>
<p><a href="https://deepmind.com/blog/article/high-fidelity-speech-synthesis-wavenet">https://deepmind.com/blog/article/high-fidelity-speech-synthesis-wavenet</a></p>
<p>They needed to predict time samples in prallel so that wavenet can be used in production, so the used a fully trained wavenet teacher, to train a smeller wavnet student, which doent depend on previous samples to produce the current sample, while still maintaining the same quality</p>
<p>-</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="End-to-end-adversarial-TTS">
<a class="anchor" href="#End-to-end-adversarial-TTS" aria-hidden="true"><span class="octicon octicon-link"></span></a>End-to-end adversarial TTS<a class="anchor-link" href="#End-to-end-adversarial-TTS"> </a>
</h2>
<h3 id="Based-on:">
<a class="anchor" href="#Based-on:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Based on:<a class="anchor-link" href="#Based-on:"> </a>
</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=WTB2p4bqtXU">https://www.youtube.com/watch?v=WTB2p4bqtXU</a></li>
<li><a href="https://deepmind.com/research/publications/2020/End-to-End-Adversarial-Text-to-Speech">https://deepmind.com/research/publications/2020/End-to-End-Adversarial-Text-to-Speech</a></li>
<li><a href="https://arxiv.org/abs/2006.03575">https://arxiv.org/abs/2006.03575</a></li>
</ul>
<p>Adversarial: means we have a generator and a descriminator which tries to detect which output is generated and which is real 
End-to-end : they take in text and output the speech</p>
<p>steps:</p>
<ul>
<li>we enter the text, then we tokenize it </li>
<li>then we use a stack of dilated conv layers to predict the length of each token</li>
<li>with this info, we can predict the center of each token </li>
<li>then we use a gaussian kernel to give a prob distributaion for the place of the token center</li>
<li>then the generator can generate the sound </li>
</ul>
<p>** Q: here we assumed that every token starts directly after the one before it, but is that the case? don't we need to add a small duration of no sound between tokens?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tacotron2">
<a class="anchor" href="#Tacotron2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tacotron2<a class="anchor-link" href="#Tacotron2"> </a>
</h2>
<h3 id="based-on:">
<a class="anchor" href="#based-on:" aria-hidden="true"><span class="octicon octicon-link"></span></a>based on:<a class="anchor-link" href="#based-on:"> </a>
</h3>
<ul>
<li><a href="https://arxiv.org/pdf/1712.05884v2.pdf">paper</a></li>
<li><a href="https://github.com/NVIDIA/tacotron2">repo</a></li>
</ul>
<p>you train tacotron-like seq2seq model to output a mel spectrogram, then pass that to wavenet to generate the wave form</p>
<p>This paper describes Tacotron 2, a fully neural TTS system that
combines a sequence-to-sequence recurrent network with attention to
predicts mel spectrograms with a modified WaveNet vocoder. The
resulting system synthesizes speech with Tacotron-level prosody and
WaveNet-level audio quality. This system can be trained directly from
data without relying on complex feature engineering, and achieves
state-of-the-art sound quality close to that of natural human speech.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="BodaSadalla98/Boda-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Boda-Blog/tts/deeplearning/2021/10/14/Text-To-Speech.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Boda-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Boda-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Boda-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>This is an unorganized posts in whih I try to summraize my readings as a way to help remember the knowlegde</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/BodaSadalla98" title="BodaSadalla98"><svg class="svg-icon grey"><use xlink:href="/Boda-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/bodasadala" title="bodasadala"><svg class="svg-icon grey"><use xlink:href="/Boda-Blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
