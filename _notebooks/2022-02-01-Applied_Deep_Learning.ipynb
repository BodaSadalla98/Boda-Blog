{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908c9a47",
   "metadata": {},
   "source": [
    "# Applied Deep Learning\n",
    "> Applied Deep Learning [Course](https://github.com/maziarraissi/Applied-Deep-Learning) \n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter,deeplearning,python]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae636b1",
   "metadata": {},
   "source": [
    "## Deep Learning overview\n",
    "* we can look at deep learning as an algorithm that writes algorithms, like a compiler\n",
    " - in this case the source code would be the data: (examples/experiences)\n",
    " - excutable code would be the deployable model \n",
    "\n",
    " * Deep: Functions compositions  $ f_l f_{l-1} .... f_1$\n",
    " * Learning: Loss, Back-propagation, and Gradient Descent\n",
    "\n",
    " * $ L(\\theta) \\approx J(\\theta)$ --> noisy estimate of the objective function due to mini-batching. That's why we call it stochastic Gradient Descent \n",
    " * why do we use the first order derivative, not the second order one (the hessian), because order of first order derivative is N, but for the hessian it's N*N, so it's computationally expensive and slow \n",
    " ### Optimizers\n",
    " * to make gradient descent faster, we can add momentum to it.\n",
    "  * another way is to use Nesttov Accelerated Gradient: the idea is to look ahead while computing the gradient, so we can add that to the momentum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3fe29",
   "metadata": {},
   "source": [
    "  * RMSprop: A mini-batch version of rprop method. the original rprop can't work with mini batches, as it doesn't consider the magnitude of the gradient, but only the sign of it, and it would multiply the gradient by a fixed factor every time depending on the sign. \n",
    "\n",
    "  ![](assets/Applied_deep_learning/rprop.png)\n",
    "\n",
    "\n",
    "  * Nestrov adaptive optimizer: the main idea is that we know that we gonna update the weights according to our average velocity so far, and also our gradient, but this can cause us to over shoot as we have a huge velocity moving down the hill, so why not update first the weights according to our velocity and see where that gets us (the look ahead term), and then we update the weights according to the gradient there "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e06d5f",
   "metadata": {},
   "source": [
    "* Adam:\n",
    "    - can take different time steps for each paramater (Adaptive steps) (took concepts from Adadelta)\n",
    "    - can also has momentum for all parameter wich can lead to faster convergence\n",
    "* Nadam: Just like Adam but with added nestrov acceleration look ahead functionality so we can slow down we go near the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53571c3",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "* A simple method to prevent the NN from overfitting \n",
    "* CNNS are less prune to overfitting becaue the weight sharing idea, that we have a set of filters fot the entire image \n",
    "* you can look at dropout as a smart way of ensembling, as it combines exponentially many different networks architectures effienctly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79537fbe",
   "metadata": {},
   "source": [
    "# Computer Vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67da4c",
   "metadata": {},
   "source": [
    "## Image Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18a38c",
   "metadata": {},
   "source": [
    "### Large Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82030f",
   "metadata": {},
   "source": [
    "#### Network In Network\n",
    "* the main idea is to put a network inside another network\n",
    "\n",
    "* they introduced multi layer preceptron conv layer which is a conv layer followed by a few FC layers\n",
    "* this idea is bisacally a (one to one convution) \n",
    "* they introduced a global averaging pooling: insted of adding a bunch of FC layers at the end of teh conv architecture, we can just average multible channels  from the last conv layer to form the output layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0739a3",
   "metadata": {},
   "source": [
    "* one by one convolution is a normal convolution with fliter size of 1 by 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b1273",
   "metadata": {},
   "source": [
    "* in conv net, we want the network to be invariant both localy and globaly, which means we still predict the photo is for a dog, even if the dog had  slight shift in pixels (local invariant), and also of the dog went to be in the lower corner of the pic isntead of the upper one (global invariant)\n",
    "* we can achieve local invariant with pooling, and deal with global invariant with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a5aec",
   "metadata": {},
   "source": [
    "\n",
    "#### VGG Net\n",
    "\n",
    "##### Local Response Normalization:\n",
    "* the idea is to normalize a pixel across nearing channels \n",
    "\n",
    "* after comparing nets with lrn and nets without, they didn't find big difference, so they stoped using it \n",
    "\n",
    "##### Data Augmentation\n",
    "* Image translations( random crops), and horizontal reflection \n",
    "* altering the intensities of the RGB channels \n",
    "* scale jittering   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c030d81",
   "metadata": {},
   "source": [
    "#### GoogleNet\n",
    "\n",
    "* You stack multiple inception modules on top of each ohter \n",
    "* the idea is that you don't have to choose which filter size to use, so why don't use them all \n",
    "* to make the network more efficient, they first projected the input with one by one convolution then applied the main filters \n",
    "* you concatinate the many filters through the channel dimension    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab15387",
   "metadata": {},
   "source": [
    "#### Batch Normalization \n",
    "\n",
    "* The main goal of batch normalization is to redude the `Internal Covariant Shift`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f025de2",
   "metadata": {},
   "source": [
    "* we can just normalize the inputs and it would work fine\n",
    "* the problem is that in each following layer, and statistics of its output would depend on its weights \n",
    "* so we also need to nomalize the inputs in hidden layers \n",
    "* here, the gradient is also going through the mean and variance operations , so it gets a snese of whats gonna happen\n",
    "\n",
    "* in inference we can't have batch-dependant mean and variance, so we use the average mean and variance for the whole dataset \n",
    "\n",
    "##### conv layers\n",
    "* for conv layers we apply normalization across every channel for every pixel in the batch of images\n",
    "* the effective bach size would be ==> m*p*q where m is the number of images in the batch and \n",
    "p,q are the image resolution \n",
    "\n",
    "##### Benifits of batch norm:\n",
    "* you can use higher learning rate, as the training is more stable \n",
    "* less sensitive to initialization \n",
    "* less sensitive to activation function \n",
    "* it has regularization effects, because thre's random mini batch every time \n",
    "* preserve gradient magintude ?? maybe --> because the jacobian doesn't scale as we scales the weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a127c4",
   "metadata": {},
   "source": [
    "#### Parametric Relu:\n",
    "\n",
    "$ f({y_i}) = \\max(0,y_i) + a_i \\min(0, y_i) $\n",
    "* if $a_i = 0$  --> Relu\n",
    "* if $a_i = 0.01$ --> Leaky Relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bceafe0",
   "metadata": {},
   "source": [
    "* the initialization of weights and biases depends on the type of activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ceec6",
   "metadata": {},
   "source": [
    "#### Kaiming Initialization  (I didn't fully understand the heavy math in this lecture, as Im still weak in statistics and variance calculations):\n",
    "\n",
    "- professor went into deep mathematical details into how to choose the intial values for weights\n",
    "* the main idea is to investigate the variance of the response in each layer, so we start by calculating the variance for the output of the layer, and we end up with many terms of the weights multiplied together, so to prevent it it from vanishing or exploding, we  want the weights to have values centred around 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127625d2",
   "metadata": {},
   "source": [
    "#### Label smoothing regularization\n",
    "- the idea is to reagularize the notwork by giving random false labels for a few examples of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f5b57",
   "metadata": {},
   "source": [
    "#### ResNet \n",
    "\n",
    "* The main idea is to make the NN deeper so that it becomes better, but the idea is that when you do that, the network gets worse, so we can fix that by adding a resdual connection.\n",
    "\n",
    "##### Identity mapping in resnets \n",
    "\n",
    "* the idea is to do no non-linear operations on the main branch(identity mapping), so that the keep a deep flow of the data both in forward and backward pathes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03f0d3",
   "metadata": {},
   "source": [
    "#### Wide Residual Networks \n",
    "\n",
    "* an attempt to make resnets wider and study if that would make them better "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf26fea",
   "metadata": {},
   "source": [
    "#### ResNext \n",
    "* just like resnets but they changed bottleneck blocks with group convolution block "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebea09",
   "metadata": {},
   "source": [
    "#### Squeeze-and-Ecxcitation Networks \n",
    "\n",
    "##### Squeeze : just a global averaging step \n",
    "##### Excitation: is just a fully connected newtwork \n",
    "##### Scaling : multiply every channel with the corresponding exctitiaiton value, more like attention \n",
    "* scaling is you paying different attention to different channels like attention models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04e8e1",
   "metadata": {},
   "source": [
    "#### Spatial Transformer Network \n",
    "* the main idea is to seperate the main object in the image, like putting a box around it and then this box can be resized, shifted, rotated. so in the end we have a focused image that has only the object, and so we can apply convolution on it and it would be easy then \n",
    "\n",
    "* the idea is to first find a good transformation parameters theta, you can do that using NN\n",
    "* then for every position in the output image, you do a bilinear sampling from the input image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82973f30",
   "metadata": {},
   "source": [
    "#### Dynamic Routing between capsuls \n",
    "\n",
    "* the idea is to make the outputs of the capsule has a norm that is the probability that an object is presenet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09096219",
   "metadata": {},
   "source": [
    "### Small Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae43e15",
   "metadata": {},
   "source": [
    "#### Knowledge Distillation\n",
    "\n",
    "* the main idea in to use an artificial data coming from the gaint model, using the normal training dataset and a smoothed the output from the giant model. then we train the distilled model using this dataset and with the same parameter `T` that we used to smooth the data. then in production we set the temperature parameter to 1 and use the distilled model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba8bbb",
   "metadata": {},
   "source": [
    "#### Network Pruning:\n",
    "*  all connections with weights below a threshold are removed from the network \n",
    "* weight are sparse now \n",
    "* then we can represent them using fewer bits\n",
    "\n",
    "#### Quantization\n",
    "* we basically cluster our weight to some centroids\n",
    "* the number of centroids for conv layers are more than the ones for FC layers why:\n",
    "    -   because conv layer filters are already sparse, we need higher level of accuracy in them\n",
    "    -   FC layers are so dense that we can tolerate fewer quantization levels \n",
    "\n",
    "#### Huffman Coding\n",
    "\n",
    "* store the more common symbols with more bits "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44692d3a",
   "metadata": {},
   "source": [
    "####  Squeeze Net\n",
    "* the idea is to squeeze the network by using one by one convolution thus use one smaller firlter sizes, then expand to make up for the squeeze that is made \n",
    "* the main idea  is to use one by one comvultion to reduce the dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c55aa",
   "metadata": {},
   "source": [
    "#### XNOR-NET\n",
    "\n",
    "* the idea to to convert the weights and inputs to binary values, and so we save a lot in memory and computation\n",
    "* the idea is to use a pre trained weights, then you try to binariez the weights by trying to approximate ==> $W = \\alpha * B $ where alpha  is postative 32 bit constant and B is a binary matrix \n",
    "* then mean we try to train by using a means square error loss function of the original weights and alpha and B \n",
    "\n",
    "* I still can't fully understand  how to binarize the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248f32e",
   "metadata": {},
   "source": [
    "#### Mobile Nets\n",
    "\n",
    "* the idea is to reduce computation complexity by doing conv for each channel sperately, and not across channels.\n",
    "* so we use number of filters as the same as the input channels\n",
    "* but then we will end up with  output size as the input size, so we still need to do one by one convolution to output the correct size\n",
    "\n",
    "#### Xception\n",
    "* unify the filters sizes for the inception, and then apply them for each channel sperately, then do one by one convolution to fix the output size\n",
    "\n",
    "#### Mobile Net V2\n",
    "* the same as MobileNet, but with Residuals connecions.\n",
    "\n",
    "#### SuffleNet\n",
    "\n",
    "* the idea is to suffle channels after doing a group convultion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114d034",
   "metadata": {},
   "source": [
    "### Auto ML\n",
    "\n",
    "* the question is can we automate architicture engineering, as we automated feature engineering in DL?\n",
    "* we can use RNN to output a probability, to sample an architicture from, then use train using this arch, and give the eval acc, as a feedback to the RNN \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf3caa",
   "metadata": {},
   "source": [
    "\n",
    "#### Regularized Evolution\n",
    "* it's basically random search + selection\n",
    "* at first you randomly choose some  architecture  train, and eval on it and push it to to the population\n",
    "* then you sample some arch. from the population\n",
    "* then u select the best acc model from your samples , and then mutate it (ie. change some of its arch.), then add it to your samples \n",
    "* then remove the oldest arch. in the population\n",
    "* you keep repeating this cycle till you evolve for C cycles (history size reaches the limit) and report the best arch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd4f8d",
   "metadata": {},
   "source": [
    "#### EfficientNet \n",
    "\n",
    "* the idea is that we do grid seach on a small network to come with the best depth scaling coefficient `d`, width scaling coefficient `w`, and resolution scalling coefficient `r`, then we try to find scaling parameter $\\phi$, that gives the best accuracy while maintaning the `flops` under the limit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aedb8a",
   "metadata": {},
   "source": [
    "### Robustness \n",
    "\n",
    "* The main goal is to make your network robust against adverarial attacks\n",
    "\n",
    "#### Intrigiong peroperties of neural networks \n",
    "* there's nothing special about individual units, and the individual features that the network learn, and they you can interpret any random direction. So, the entire spacd matters \n",
    "* neural networks  has blind spots, this  means you can add small pertirbations to an image, they are not noticable to the human eye, but they make the network wrongly classify the image  \n",
    "* Adversiral examples tend to stay hard even for models trained with different hyper-parameters, or ever for different training datasets \n",
    "\n",
    "* you can train your network to defend against attacks but that's expensive, as: first, you have to train your network, then train it again to find some adversiral attacks, then add those examples to the training set, and finally train for a third time.\n",
    "\n",
    "* small perturbation to the image, leads to huge perturbation to the activation, due to high dimensionality\n",
    "#### untargeted adversiral examples\n",
    "* fast gradient sign: using the trick of the sign of the loss gradient, and add it to the original image to generate an adversiral example \n",
    "* then you can just add a weighted loss, one for the  orginal example, and another for the adversiral one, so that the network would be more robust to adversiral examples \n",
    "\n",
    "#### Towards Evaluating the Robustness of Neural Networks\n",
    "* another way to generate targetted adversiral examples is: to choose a function that forces the network to make the logits for the targeted example the biggest, so that this class is selected. \n",
    "\n",
    "![](assets/Applied_deep_learning/adversiral-attack-algo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa88c77",
   "metadata": {},
   "source": [
    "### Visualizing & Understanding\n",
    "* now we want to debug our network, to understand how it works\n",
    "* so we want do a backward pass, by inverting our forward pass, but then we habe a problem with pooling layers as we subsamples the input.\n",
    "* so we store the locations for the max pixels that we choose in our pooling operation, so that we can upsample the input again in the backward pass.\n",
    "* we call these max locations, switches\n",
    "* the main idea is, visualising the feature maps, gonna help you modify the network \n",
    "* you can have two models that have the same output for the same input but which one do you trust more?\n",
    "    - to answer that, you need to see which features each one of them focuses on, so if one of them focuses on features that are important to classfication, then this model is more trustworthy \n",
    "#### LIME: Local Interpretable Model-agnsortic Explanations\n",
    "* you want to make trust the model, meaning that you wanna maek sure the model parioritized the important features\n",
    "* but you can't interprete non linear models, so the idea is to make a locally linear model, that have the same output for your local input example, then use this linear model to get the features that the model parioritrized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f6e37",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867f7ff",
   "metadata": {},
   "source": [
    "## Image Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3211165",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1892e1f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
